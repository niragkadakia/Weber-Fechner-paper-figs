\documentclass[letterpaper,12pt]{article}
%\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{fullpage}
\usepackage{calc}
\usepackage{slashed}
\usepackage{xfrac}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=cyan,
}
\title{Supporting Information}


\begin{document}
\maketitle

\section*{Odor-receptor binding model}

We model an odor as an $N$-dimensional vector ${\mathbf s=[ s_1,...,s_N]}$, where $s_i > 0$ are the concentrations of individual volatile molecules (odorants) comprising the odor. 
The olfactory sensory system is modeled as a collection of $M$ distinct Or/Orco complexes, each of which can be bound with any one of the odorant molecules, and can be either active (firing) inactive (quiescent). We only consider competitive binding, so a complex is bound with one odorant at most. With $N$ possible odorants, receptor $a$ resides in one of $2N+2$ possible states, \{$R_a$, $R^*_a$, $R_a$-$s_i$, $R^*_a$-$s_i$\}, indicating receptors that are unbound/inactive, unbound/active, inactive/bound to odorant $i$, and active/bound to odorant $i$, respectively. We set $N = 150$ and $M = 50$ throughout.

In the mean-field limit, the binding dynamics of these $2N + 2$ states are described by the master equations:

\begin{align}
\frac{d[R_a\text{-}s_i]}{dt} &= k^+_{ia}s_i[R_a] - k^-_{ia}[R_a\text{-}s_i] \label{eq:Meq_inactive_bind_rate}\\
\frac{d[R^*_a\text{-}s_i]}{dt} &= k^{*+}_{ia}s_i[R^*_a] - k^{*-}_{ia}[R^*_a\text{-}s_i],
\label{eq:Meq_active_bind_rate}
\end{align}
when receptor $R_a$ is either inactive (Eq.~\ref{eq:Meq_inactive_bind_rate}) or active (Eq.~\ref{eq:Meq_active_bind_rate}). Further, transitions between inactive and active states are described in the mean limit via:
\begin{align}
\frac{d[R_a]}{dt} &= w^{\text{u}+}_a [R_a] - w^{\text{u}-}_a [R^*_a] \label{eq:Meq_unbound_active_rate}\\
\frac{d[R^*_a\text{-}s_i]}{dt} &=  w^{\text{b}+}_{ia} [R_a\text{-}s_i] - w^{\text{b}-}_{ia}  [R^*_a\text{-}s_i],
\label{eq:Meq_bound_active_rate}
\end{align}
when receptor $R_a$ is either unbound (Eq.~\ref{eq:Meq_unbound_active_rate}) or bound (Eq.~\ref{eq:Meq_bound_active_rate}). The corresponding disassociation constants in terms of the binding transition rates are:


\begin{align}
K_{ai} = \frac{k^-_{ai}}{k^+_{ai}} \nonumber \\
K^*_{ai} = \frac{k^{*-}_{ai}}{k^{+*}_{ai}} 
\label{eq:Kd}
\end{align}

Following~\cite{srinivas_elife}, we assume that in steady state, the active firing state of an Or/Orco complex is energetically suppressed from the inactive state through corresponding Boltzmann factors:

\begin{align}
\frac{[R^*_a]}{[R_a]} &= \frac{w^{\text{u}+}_a}{w^{\text{u}-}_a} \equiv e^{-\epsilon_a} \label{eq:epsilon_unbound} \\
\frac{[R^*_a\text{-}s_i]}{[R_a\text{-}s_i]} &= \frac{w^{\text{b}+}_{ia}}{w^{\text{b}-}_{ia}} \equiv e^{-\epsilon^{\text b}_{ia}}.\label{eq:epsilon_bound}
\end{align}
These energies are related through detailed balance, which we assume. Applying detailed balance to a given 4-cycle 
\begin{align}
R_a \rightarrow R_a^* \rightarrow R_a^*\text{-}s_i \rightarrow R_a\text{-}s_i \rightarrow R_a
\end{align}
gives
\begin{align}
\frac{w^{\text{u}+}_a}{w^{\text{u}-}_a}\frac{k^{*+}_{ia}}{k^{*-}_{ia}}\frac{w^{\text{b}-}_{ia}}{w^{\text{b}+}_{ia}}\frac{k^{-}_{ia}}{k^{+}_{ia}} \equiv 1,
\label{eq:detailed_balance}
\end{align}
which, in conjunction with Eqs.~\ref{eq:Kd}, \ref{eq:epsilon_unbound}, and \ref{eq:epsilon_bound}, gives
\begin{align}
\epsilon_{ai}^{\text b} = \epsilon_{a, \textup{act}} + \ln\left[\frac{K^*_{ai}}{K_{ai}}\right].
\label{testing_equation}
\end{align}
Assuming the binding dynamics are fast, then the probability that receptor $a$ is bound by ligand~$i$ when inactive and active can be derived from  Eqs.~\ref{eq:Meq_inactive_bind_rate} and \ref{eq:Meq_active_bind_rate} as
\begin{align}
p^{\text b}_{ai} = \frac{s_i/K_{ai}}{1 + \sum_j^Ns_j/K_{aj}} \label{eq:bound_prob_ai_inactive} \\
p^{\text b, *}_{ai} = \frac{s_i/K^*_{ai}}{1 + \sum_j^Ns_j/K^*_{aj}} \label{eq:bound_prob_ai_active}.
\end{align}
The average  activity $A_a$ of complex $a$ is the likelihood that the complex is active, unbound or unbound (equivalantly, the proportion of Or/Orco complexes in a given ORN that are active):
\begin{align}
A_a = \frac{[R^*_a] + \sum_i^N[R^*_a\text{-}s_i]}{[R^*_a] + \sum_i^N[R^*_a\text{-}s_i] + {[R_a] + \sum_i^N[R_a\text{-}s_i]}}.
\end{align} 
Using the master equations between active and inactive states Eq.~\ref{eq:Meq_unbound_active_rate} and \ref{eq:Meq_bound_active_rate}, $A_a$  obeys the master equation
\begin{align}
\frac{dA_a}{dt} &= w^+_a(1 - A_a) + w^-_aA_a
\label{eq:dadt}
\end{align}
with effective transition rates
\begin{align}
w^+_a &= \sum_i^Np^{\text b}_{ai} w^{\text u +}_{ai} + p_{a}w^{\text u}_a 
\end{align}
and analogously for $w_a^-$. Setting Eq.~\ref{eq:dadt} to zero gives the steady state average activity level of Or/Orco complex $a$:
\begin{align}
A_a = \left(1 + e^{\epsilon_{a, \textup{act}}}\frac{1 + \sum_i^N s_i/K_{ai}}{1 + \sum_i^N s_i/K^*_{ai}}\right)^{-1}. \tag{\ref{eq:steady_state_act_OR}}
\end{align}
	
\section*{ORN firing response}

Receptor activity $A_a$ is a measure of cation influx into ORNs elevates the ORN membrane voltage, which can then incite a sustained firing response. A faithful representation of this process would require a Hodgkin-Huxley-type model. These dynamics can be largely captured by a linear-nonlinear response, which we adopt here. 

\section*{Generation of binding matrices $K^*_{ia}$}
 TODO

\section*{Compressed sensing decoding of ORN response}
We decode ORN responses to infer odor signal identities using an abstraction intended to mimic the neural computations underlying odor identification in the \textit{Drosophila} mushroom body. While we make no assumptions that the compressed sensing (CS) algorithm (or one like it) is being utilized in actuality, this framework nonetheless informs our understanding of how the neural representation of odor identity is maintained or lost when passed through a distributed ORN repertoire. In this sense, CS is somewhat of an upper bound on how well a real neural computation might perform in decompressing ORN responses.

We assume that ORN firing rates are linear in the Or/Orco complex activity; for simplicity we let this transform be the identity. Though subsequent neural circuitry, particularly from the glomeruli in the AL to the Kenyon cells in the MB further mix and scramble these responses, we focus here on the information transfer at the sensory periphery alone. In any case, as demonstrated previously~\cite{vijay_1}, we expect that these neural computations would only improve the representation of neural identity, so we expect no negative ramifications for our findings.

CS addresses the problem of determining a sparse signal from a set of linear measurements, when the number of measurements is less than the signal dimension. Specifically, it is a solution to 
\begin{align}
\mathbf y = \mathbf R\mathbf s,
\label{eq:CS_constraints}
\end{align} where $\mathbf s \in \mathbb{R}^N$ and $\mathbf a\in \mathbb{R}^M$ are vectors of signals and responses, respectively, and $\mathbf R$ is the measurement matrix. Since measurements are fewer than signal components, then $M < N$, whereby $\mathbf R$ is wide rectangular and so Eq.~\ref{eq:CS_constraints} cannot be simply inverted to produce $\mathbf s$. The idea of CS is to utilize the knowledge that $\mathbf s$ is sparse, i.e.g only $K$ of its components, $K \ll N$ are nonzero. Both the measurements and sparsity are thus combined into a single constrained optimization routine:
\begin{align}
\hat s_i = \textup{argmin} \sum_i^N |s_i| \quad \textup{such that } \mathbf y = \mathbf R\mathbf s
\label{eq:CS}
\end{align}
where $\hat s_i$ are the optimal estimates of the signal components and the sum, which is known as the $L_1$ norm of $\mathbf s$, is a natural metric of sparsity. 

Importantly, the $L_1$ norm is a convex operation and the constraints are linear, so the optimization has a unique global minimum. To incorporate the nonlinear response of our encoding model into this linear framework, we assume that the responses are generated through the full nonlinear steady state response, Eq.~\ref{eq:steady_state_act}, but that the measurement matrix needed for decoding uses a linear approximation of this transformation.  Expanding Eq.~\ref{eq:steady_state_act} around $s_0 = s_i - \Delta s_i$ gives
\begin{align}
A_a &\approx A_{a, 0} + \Delta A_a \label{eq:CS_act_approx} \\
\Delta A_a &= \sum_i^NR_{ia}\big|_{s_0}\Delta s_i \label{eq:CS_dAct_approx}\\
A_{a, 0} &= \frac{\sum_1^N s_0/K_{ia}^*}{\sum_1^N s_0/K_{ia}^* + e^{\epsilon_a}} \label{eq:CS_act0_approx} \\
R_{ia}\big|_{s_0} &=  \frac{e^{\epsilon_a}/K_{ia}^*}{(\sum_i^Ns_0/K_{ia}^* + e^{\epsilon_a})^2},
\label{eq:CS_gain_approx}
\end{align}
where we work in the approximation $K^*_{ia} \ll~s_0 \ll K_{ia}$. We assume that the neural system has access to the linearized response, Eq.~\ref{eq:CS_gain_approx}, but must infer the excess signals $\Delta s_i$ from the excess activity $\Delta A_a$. Corresponding to the CS framework, therefore, $\Delta \mathbf {A} \rightarrow \mathbf y$, $\Delta \mathbf s \rightarrow \mathbf s$, and $R_{ia}\big|_{s_0} \rightarrow \mathbf R$. We optimize the cost function in Eq.~\ref{eq:CS} using sequential least squares programming, implemented in Python through using the scientific package SciPy.

\section*{Or/Orco  energies of activation $\epsilon_a$ and enforcement of Weber's Law}
Free energies are considered receptor-independent throughout, with the exception of dynamically adaptive system in a temporal odor environment (Figs.~\ref{fig:temporal_coding} and \ref{fig:temporal_coding_2}). To enforce Weber's Law, we assume the receptor activities feed back onto $\epsilon_a$ through the free energies. For the static case, adaptation is perfect, whereby Or/Orco activities are pegged to perfectly adapted values $\bar {A}_{a}$. Incorporating this into Eq.~\ref{eq:steady_state_act}, and assuming  $K^*_{ia} \ll s \ll K_{ia}$, gives
\begin{align}
\bar \epsilon_a &= \ln\left(\frac{1-\bar {A}_{a}}{\bar {A}_{a}}\right) + \ln\left(\sum_i^N\frac{s_i}{K_{ia}^*}\right).
\label{eq:adapted_epsilon}
\end{align}
Assuming that the excess signals are small, $\Delta s_i < s_0$, this gives 
\begin{align}
\epsilon_a \approx \ln(s_0) + \epsilon_{a, 0},
\label{eq:WL_approx}
\end{align} 
where $\epsilon_{a, 0}$ are receptor-dependent constants. In the static case, we choose these constants such that $\epsilon_{a}$ in both adaptive and non-adaptive systems are equivalent, equal to $\epsilon_{\text {L}}$, at a given low concentration, $s_{0, \text L}$.  Below this concentration, we assume adaptation is not in effect, so $\epsilon_a  = \epsilon_{\text {L}}$.  

It is important to note that while the linearized gain Eq.~\ref{eq:CS_gain_approx} utilized by the decoding algorithm appears to rely on $\epsilon_a$, by the above argument $\epsilon_a$ can in principle be determined by firing rates alone. That is, $\epsilon_a$ is inferred in time through integration of Eq.~\ref{eq:WL_dynamics}, which relies only on the current ORN activity.


\begin{table*}[!tb]
	\centering
	{\small
		\begin{tabular}{ccccccccccccccc}
			Figure & $N$& $M$ & $K$ & $\mu_{a, \text L}$ & $\mu_{a, \text H}$ & $\nu_{a, \text L}$ & $\nu_{a, \text H}$ & $\epsilon_{a, 0}$ & $\epsilon_{\text {L}}$  & $\epsilon_{\text {H}}$  & $s_{0, \text L}$ & $s_k$ & $s_{k, \text F}$\\[0.1cm]
			
			\hline \\[-0.2cm]
			\smallskip
			
			\ref{fig:tuning_curves_c} & 200 & 40 & 6 & $2\cdot 10^{-4}$ & $10^{-3}$ & $10^{-2}$ & 1.0 & 5.4 & 5.4 & 10  & - & $ \mathcal N\left(\frac{s_0}{5}, \frac{s_0}{15}\right)$ & --\\
			
			\ref{fig:decoding_a} & 100 & 50 & 7 & 0.5 & 0.5 & 0.8 & 0.8 & 5.4 & 3.1 & 10  & $10^{-1}$ & $ \mathcal N\left(\frac{s_0}{3}, \frac{s_0}{15}\right)$ & -- \\
			
			\ref{fig:decoding_b} & 100 & 50 & 7 & 0.5 & 0.6 & 0.6 & 0.9 & 5.4 & 3.1 & 10 & $10^{-1}$ & $ \mathcal N\left(\frac{s_0}{3}, \frac{s_0}{15}\right)$ & ---\\
			
			\ref{fig:decoding_c} & 100 & 50 & 7 & 0.5 & 0.6 & 0.6 & 0.9 & 5.4 & 3.1 & 10 & $10^{-1}$ & $ \mathcal N\left(\frac{s_0}{3}, \frac{s_0}{15}\right)$ & -- \\
			
			\ref{fig:signal_discrimination_a}-\ref{fig:signal_discrimination_h} & 100 & 50 & 7 & 0.5 & 0.6 & 0.6 & 0.9 & 5.4 & 3.1 & 10 & $10^{-1}$ & $ \mathcal N\left(\frac{s_0}{3}, \frac{s_0}{15}\right)$ & $ \mathcal N(1, \frac{1}{5})$ \\
			
			\ref{fig:temporal_coding} & 100 & 50 & 7 & 0.5 & 0.6 & 0.6 & 0.9 & -- & -- & -- & $10^{-2}$ & $ \mathcal N\left(\frac{s_0}{3}, \frac{s_0}{9}\right)$ & -- \\
			
			\ref{fig:temporal_coding_2} & 100 & 50 & 7 & 0.5 & 0.6 & 0.6 & 0.9 & -- & -- & -- & $10^{-2}$ & $ \mathcal N\left(\frac{s_0}{3}, \frac{s_0}{9}\right)$ & -- \\
		\end{tabular}
	}
	\caption{Parameters for simulations in all of the figures.}
	\label{tab:params}
\end{table*}



\section*{Odor signals}
Odor signals $\mathbf s$ are $N$-dimensional vectors presumed sparse whereby only $K$ components, $s_k$ are nonzero,  $K~\ll~N$. The magnitudes of the nonzero components $s_k$ are denoted $s_0 + \Delta s_k$. Here, $\Delta s_k$ is a random vector, while $s_0$ is both the center of linearization and, in the case of the adaptive system, the value dictating the strength of adaptive feedback $\epsilon_a\sim\ln\langle s_0 \rangle$. 

All the signal intensities are in arbitrary units, as they can be scaled to any range by a corresponding shift in the scales of $K_{ia}$ and $K^*_{ia}$.

\section*{Dynamic adaptation}

Dynamic adaptation is enforced through
\begin{align}
	\frac{d\epsilon_a(t)}{dt} &= \frac{1}{\tau_a}\left[A_a - \bar {A}_{a}\right].
	\tag{\ref{eq:WL_dynamics}}
\end{align}
The perfectly adapted activity levels $\bar {A}_{a}$ are determined by evaluating Eq.~\ref{eq:steady_state_act} at a given odor intensity, $s_{0, \text{L}}$, corresponding to a minimum stimulus at which adaptation takes effect. The decoding step is assumed instantaneous, so decoded odor identity $\mathbf {\hat s}$ is determined by the current value of $\epsilon_a$ (which, by virtue of Eq.~\ref{eq:WL_dynamics}, is determined by ORN activity a short time prior).

For the simulations with two fluctuating odors (Figs.~\ref{fig:temporal_coding_2}), the traces shown correspond to the values of $s_0$ (in blue) and $s_{0, \text{b}}$ (orange), where $s_{0, \text{b}}$ is the baseline concentration of the background odor components, to which the excess signals $\Delta s_{k, \text {b}}$ are added to set the individual odorant concentrations. We choose $\Delta s_{k, \text {b}}~\sim~\mathcal N(s_{k, \text {b}}/3, s_{k, \text {b}}/9)$.


\end{document}
